{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_L1():\n",
    "    f = open(\"english-hindi-dictionary.txt\", \"r\")\n",
    "    eng_to_hin = {}\n",
    "    for x in f:\n",
    "        words = x.strip().split(\"|||\")\n",
    "        eng = lemmatizer.lemmatize(words[0].strip())\n",
    "        hin = words[1][:words[1].find(\"\\n\")].strip()\n",
    "        if eng not in eng_to_hin:\n",
    "            eng_to_hin[eng] = list()\n",
    "        eng_to_hin[eng].append(hin)\n",
    "\n",
    "    df = pd.read_csv(\"BingLiu.csv\")\n",
    "    ar = df.values\n",
    "    bing_eng_hin_l1 = {}\n",
    "    for row in ar:\n",
    "        row = row[0].split(\"\\t\")\n",
    "        wrd = row[0].strip()\n",
    "        pol = row[1].strip()\n",
    "        wrd_bing = lemmatizer.lemmatize(wrd)\n",
    "        key = (wrd_bing,pol)\n",
    "        if wrd_bing in eng_to_hin:\n",
    "            if wrd_bing not in bing_eng_hin_l1:\n",
    "                bing_eng_hin_l1[key] = list()\n",
    "            for hin in eng_to_hin[wrd_bing]:\n",
    "                if not str.isalpha(hin):\n",
    "                    bing_eng_hin_l1[key].append(hin)\n",
    "    return bing_eng_hin_l1,eng_to_hin"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_w2v_models():\n",
    "    data_file = \"english.txt\"\n",
    "    def read_input_eng(input_file):\n",
    "        with open (input_file, 'r') as f:\n",
    "            for i, line in enumerate (f):\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "    eng_documents = list (read_input_eng (data_file))\n",
    "    data_file = \"hindi.txt\"\n",
    "    def read_input_hin(input_file):\n",
    "        with open (input_file, 'r') as f:\n",
    "            for i, line in enumerate (f):\n",
    "                if \"\\n\" in line:\n",
    "                    line = line[:line.find(\"\\n\")].strip()\n",
    "                yield  line.split(\" \")\n",
    "    hin_documents = list (read_input_hin (data_file))\n",
    "    model_w2v_en = gensim.models.Word2Vec(eng_documents)\n",
    "    model_w2v_en.train(eng_documents,total_examples=len(eng_documents),epochs=150)\n",
    "    model_w2v_hi = gensim.models.Word2Vec (hin_documents)\n",
    "    model_w2v_hi.train(hin_documents,total_examples=len(hin_documents),epochs=150)\n",
    "    return model_w2v_en,model_w2v_hi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model_w2v_en.most_similar(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_glove_models():\n",
    "    word2vec_output_file = 'word2vec_eng.txt'\n",
    "    # glove2word2vec(\"vectors.txt\", word2vec_output_file)\n",
    "    model_glove_en = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "    word2vec_output_file = 'word2vec.txt'\n",
    "    # glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "    model_glove_hi = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "    return model_glove_en,model_glove_hi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def iterate(bing_eng_hin_l1,model_w2v_hi,model_glove_en,model_glove_hi,eng_to_hin,model_w2v_en):\n",
    "    top = 150\n",
    "    ans = {}\n",
    "    for key in bing_eng_hin_l1:\n",
    "            engList = []\n",
    "            hinList = []\n",
    "            eng_wrd = key[0]\n",
    "            if eng_wrd in model_w2v_en.wv.vocab:\n",
    "                engList += model_w2v_en.most_similar(eng_wrd,topn=top)\n",
    "            if eng_wrd in model_glove_en.wv.vocab:\n",
    "                engList += model_glove_en.most_similar(eng_wrd,topn=top)\n",
    "\n",
    "            hin_temp_list = bing_eng_hin_l1[key]\n",
    "\n",
    "            for hin_wrd in hin_temp_list:\n",
    "                if hin_wrd in model_w2v_hi.wv.vocab:\n",
    "                    hinList += model_w2v_hi.most_similar(hin_wrd,topn=top)\n",
    "                if hin_wrd in model_glove_hi.wv.vocab:\n",
    "                    hinList += model_glove_hi.most_similar(hin_wrd,topn=top)\n",
    "\n",
    "            for eng in engList:\n",
    "                eng = lemmatizer.lemmatize(eng[0])\n",
    "                for hin in hinList:\n",
    "                    if eng in eng_to_hin:\n",
    "                        if hin[0] in eng_to_hin[eng]:\n",
    "                            ans[eng] = hin[0]\n",
    "    return ans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new words generated in L1\n",
      "blue : ब्लू\n",
      "listen : सुन\n",
      "boyfriend : प्रेम\n",
      "heavy : भार\n",
      "case : के\n",
      "they : व\n",
      "that : व\n",
      "are : है\n",
      "purchased : खरीद\n",
      "seen : देख\n",
      "heard : सुन\n",
      "meet : मिले\n",
      "saw : देख\n",
      "bought : खरीद\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-10a0670172d9>:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if eng_wrd in model_glove_en.wv.vocab:\n",
      "<ipython-input-31-10a0670172d9>:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if hin_wrd in model_glove_hi.wv.vocab:\n",
      "<ipython-input-31-10a0670172d9>:17: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  hinList += model_w2v_hi.most_similar(hin_wrd,topn=top)\n",
      "<ipython-input-31-10a0670172d9>:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  engList += model_w2v_en.most_similar(eng_wrd,topn=top)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    bing_eng_hin_l1,eng_to_hin = get_L1()\n",
    "    model_w2v_en,model_w2v_hi = get_w2v_models()\n",
    "    model_glove_en,model_glove_hi = get_glove_models()\n",
    "    print(\"new words generated in L1\")\n",
    "    ans = iterate(bing_eng_hin_l1,model_w2v_hi,model_glove_en,model_glove_hi,eng_to_hin,model_w2v_en)\n",
    "    for key in ans:\n",
    "        print(\"{} : {}\".format(key,ans[key]))\n",
    "main()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}